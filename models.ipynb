{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "from scjpnlib.utils.file_io import FileManager\n",
    "import scjpnlib.utils as scjpnutils\n",
    "import pickle\n",
    "import json\n",
    "from IPython.core.display import HTML, Markdown\n",
    "import html2text\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scjpnlib.utils.skl_transformers import LabelEncodingTransformer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import dask_ml.model_selection as dcv\n",
    "from dask.distributed import Client\n",
    "import joblib\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier \n",
    "# import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "K = 3 # num folds for cross-val\n",
    "cross_val_score_K = 5\n",
    "n_jobs = 8\n",
    "\n",
    "LOG_MODEL_TRIALS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Configs for this Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'dask': {'use': False,\n  'is_remote': False,\n  'local': {'n_workers': 1, 'n_jobs': 8, 'memory_limit': '16GB'},\n  'remote': {'scheduler_address': '35.230.13.87'}},\n 'SEED': 42,\n 'DecisionTreeClassifier': {'run': False,\n  'trials': {'run': False,\n   'array': [{'gridsearch': {'run': False,\n      'param_grid': {'criterion': ['entropy', 'gini'],\n       'splitter': ['best'],\n       'max_depth': [10, 50, 75, None],\n       'min_samples_split': [2],\n       'max_features': ['auto', 'sqrt', 'log2']},\n      'last_best': {'criterion': 'entropy',\n       'splitter': 'best',\n       'max_depth': None,\n       'min_samples_split': 2,\n       'max_features': 'sqrt'}}}]},\n  'params': {'criterion': 'entropy',\n   'splitter': 'best',\n   'max_depth': None,\n   'min_samples_split': 2,\n   'max_features': 'sqrt'}},\n 'RandomForestClassifier': {'run': False,\n  'trials': {'run': False,\n   'array': [{'gridsearch': {'run': False,\n      'param_grid': {'bootstrap': [True, False],\n       'criterion': ['entropy', 'gini'],\n       'max_features': ['auto', 'sqrt', 'log2'],\n       'max_depth': [10, 50, 75, None],\n       'n_estimators': [100, 500, 1000]},\n      'last_best': {'bootstrap': True,\n       'criterion': 'entropy',\n       'max_depth': 75,\n       'max_features': 'auto',\n       'n_estimators': 1000}}}]},\n  'params': {'bootstrap': True,\n   'criterion': 'entropy',\n   'max_depth': 75,\n   'max_features': 'auto',\n   'n_estimators': 1000}},\n 'XGBClassifier': {'run': True,\n  'trials': {'run': True,\n   'array': [{'gridsearch': {'run': True,\n      'param_grid': {'n_estimators': [100, 500, 750, 1000]},\n      'last_best': {'n_estimators': 100}}},\n    {'gridsearch': {'run': True,\n      'param_grid': {'max_depth': [3, 5, 10, 22, 50]},\n      'last_best': {'max_depth': 3}}},\n    {'gridsearch': {'run': True,\n      'param_grid': {'learning_rate': [0.1, 0.3, 0.6, 1.0]},\n      'last_best': {'learning_rate': 0.1}}},\n    {'gridsearch': {'run': True,\n      'param_grid': {'min_child_weight': [1, 3, 5]},\n      'last_best': {'min_child_weight': 1}}},\n    {'gridsearch': {'run': True,\n      'param_grid': {'subsample': [0.1, 0.25, 0.5, 1.0]},\n      'last_best': {'subsample': 1.0}}},\n    {'gridsearch': {'run': True,\n      'param_grid': {'gamma': [0, 1, 2, 5, 10]},\n      'last_best': {'gamma': 5}}}]},\n  'params': {'learning_rate': 0.1,\n   'max_depth': 3,\n   'min_child_weight': 1,\n   'subsample': 1.0,\n   'gamma': 5,\n   'n_estimators': 100}}}"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "fm = FileManager()\n",
    "\n",
    "models_config = fm.load_json('models-config.txt')\n",
    "models_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_data_cached = 'data_cached' in models_config\n",
    "data_config = models_config['data_cached'] if is_data_cached else fm.load_json('eda-config.txt')\n",
    "digest = data_config['digest'] if is_data_cached else scjpnutils.json_to_md5_hash_digest(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "EDA description: (digest: 2d7d3126b4f539a5c747b7bed497626b) 0.10 test_ratio, flat insig cat hat handling with threshold 10; location based on ward\n"
    }
   ],
   "source": [
    "print(f\"EDA description: {'CACHED ' if is_data_cached else ''}(digest: {digest}) {data_config['eda_desc']['short']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "modeling results will be saved to: models-results-2d7d3126b4f539a5c747b7bed497626b.json\n"
    }
   ],
   "source": [
    "model_results_fname = scjpnutils.get_model_result_fname(data_config, data_kwargs={'is_cached':is_data_cached})\n",
    "print(f\"modeling results will be saved to: {model_results_fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "model_results['digest'] = digest\n",
    "model_results['modeling_results'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "<h2>Load TEST/TRAIN Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = models_config['SEED']\n",
    "model_results['seed'] = SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loaded wrangled-labeled-data-train-2d7d3126b4f539a5c747b7bed497626b.csv\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 53460 entries, 0 to 74247\nData columns (total 22 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   amount_tsh         53460 non-null  float64\n 1   funder             52583 non-null  float64\n 2   gps_height         53460 non-null  int64  \n 3   installer          52582 non-null  float64\n 4   longitude          53460 non-null  float64\n 5   latitude           53460 non-null  float64\n 6   basin              53460 non-null  float64\n 7   region_code        53459 non-null  float64\n 8   district_code      53460 non-null  float64\n 9   population         53460 non-null  int64  \n 10  public_meeting     53460 non-null  bool   \n 11  scheme_management  53460 non-null  float64\n 12  scheme_name        52880 non-null  float64\n 13  permit             53460 non-null  bool   \n 14  extraction_type    53460 non-null  float64\n 15  management         53460 non-null  float64\n 16  payment_type       53460 non-null  float64\n 17  water_quality      53460 non-null  float64\n 18  quantity           53460 non-null  float64\n 19  source             53460 non-null  float64\n 20  waterpoint_type    53460 non-null  float64\n 21  pump_age           53460 non-null  int64  \ndtypes: bool(2), float64(17), int64(3)\nmemory usage: 8.7 MB\n"
    }
   ],
   "source": [
    "fname = scjpnutils.get_data_fname(data_config, data_kwargs={'is_labels':False,'type':'train','is_cached':is_data_cached})\n",
    "data_train = pd.read_csv(fname, index_col=0).sort_index()\n",
    "print(f\"loaded {fname}\\n\")\n",
    "\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([    0,     1,     2,     3,     5,     7,     8,     9,    11,\n               12,\n            ...\n            74235, 74236, 74237, 74238, 74239, 74240, 74242, 74243, 74246,\n            74247],\n           dtype='int64', name='id', length=53460)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loaded labels-train-2d7d3126b4f539a5c747b7bed497626b.csv\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 53460 entries, 0 to 74247\nData columns (total 1 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   status_group  53460 non-null  object\ndtypes: object(1)\nmemory usage: 835.3+ KB\n"
    }
   ],
   "source": [
    "fname = scjpnutils.get_data_fname(data_config, data_kwargs={'is_labels':True,'type':'train','is_cached':is_data_cached})\n",
    "y_train = pd.read_csv(fname, index_col=0).sort_index()\n",
    "print(f\"loaded {fname}\\n\")\n",
    "\n",
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([    0,     1,     2,     3,     5,     7,     8,     9,    11,\n               12,\n            ...\n            74235, 74236, 74237, 74238, 74239, 74240, 74242, 74243, 74246,\n            74247],\n           dtype='int64', name='id', length=53460)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "y_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 0, 1])"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "let_labels = LabelEncodingTransformer(['status_group'])\n",
    "y_train = let_labels.fit_transform(y_train)\n",
    "y_train.status_group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['functional', 'functional needs repair', 'non functional'],\n      dtype=object)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "let_labels.labelencoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_train = list(let_labels.labelencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       amount_tsh    funder  gps_height  installer  longitude   latitude  \\\nid                                                                         \n0             0.0  0.801370           0   0.773171  33.125828  -5.118154   \n1             0.0  0.429167        1978   0.469828  34.770717  -9.395642   \n2             0.0  1.006849           0   1.135593  36.115056  -6.279268   \n3            10.0  0.234811        1639   0.234811  37.147432  -3.187555   \n5            50.0  0.391156          28   0.440994  39.286124  -6.972403   \n...           ...       ...         ...        ...        ...        ...   \n74240         0.0  0.702811        1183   0.623209  37.007726  -3.280868   \n74242         0.0  0.849020           0   0.889418  33.724987  -8.940758   \n74243         0.0  1.315789        1188   0.835007  33.963539  -1.429477   \n74246        50.0  1.066667        1428   1.066667  35.630481  -7.710549   \n74247        50.0  0.463333         965   0.822742  35.432998 -10.639270   \n\n          basin  region_code  district_code  population  ...  permit  \\\nid                                                       ...           \n0      0.918364     1.104651       0.938982           0  ...    True   \n1      0.674483     0.413474       0.700044          20  ...   False   \n2      0.907618     0.988636       0.700044           0  ...    True   \n3      0.744938     0.720877       0.817451          25  ...    True   \n5      0.907618     1.025391       1.142857        6922  ...   False   \n...         ...          ...            ...         ...  ...     ...   \n74240  0.744714     0.633807       0.731299         350  ...   False   \n74242  0.674232     0.891332       0.814178           0  ...   False   \n74243  0.908266     1.070122       0.934446          95  ...   False   \n74246  0.674232     0.413474       0.819620           1  ...    True   \n74247  1.183882     0.816976       0.813999         900  ...    True   \n\n       extraction_type  management  payment_type  water_quality  quantity  \\\nid                                                                          \n0             0.620690    0.922653      1.081903       0.894147  0.623053   \n1             0.664444    0.922604      1.026985       0.791310  0.622992   \n2             1.200070    0.922604      0.598954       0.791310  0.857747   \n3             0.700661    0.430082      0.598954       0.791310  0.622992   \n5             0.849675    0.480203      0.598731       0.791271  0.623053   \n...                ...         ...           ...            ...       ...   \n74240         0.700661    0.537885      1.081903       0.791310  0.857615   \n74242         0.700661    0.702026      0.688219       0.791271  0.623053   \n74243         0.849885    0.922653      1.026907       0.791290  0.623053   \n74246         0.700586    0.922604      0.598731       0.791310  1.943795   \n74247         1.647846    0.922629      0.598731       0.791271  1.943795   \n\n         source  waterpoint_type  pump_age  status_group  \nid                                                        \n0      0.953635         0.705496         0             2  \n1      0.953516         0.705496         3             0  \n2      0.976612         1.161586         0             0  \n3      0.680494         0.677816        14             0  \n5      0.976431         1.161259         0             0  \n...         ...              ...       ...           ...  \n74240  0.655623         0.677816         1             0  \n74242  0.735928         0.677816         0             0  \n74243  1.560209         1.161586        29             2  \n74246  0.680494         0.677781        11             2  \n74247  0.735719         0.677816         4             2  \n\n[53460 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>amount_tsh</th>\n      <th>funder</th>\n      <th>gps_height</th>\n      <th>installer</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>basin</th>\n      <th>region_code</th>\n      <th>district_code</th>\n      <th>population</th>\n      <th>...</th>\n      <th>permit</th>\n      <th>extraction_type</th>\n      <th>management</th>\n      <th>payment_type</th>\n      <th>water_quality</th>\n      <th>quantity</th>\n      <th>source</th>\n      <th>waterpoint_type</th>\n      <th>pump_age</th>\n      <th>status_group</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.801370</td>\n      <td>0</td>\n      <td>0.773171</td>\n      <td>33.125828</td>\n      <td>-5.118154</td>\n      <td>0.918364</td>\n      <td>1.104651</td>\n      <td>0.938982</td>\n      <td>0</td>\n      <td>...</td>\n      <td>True</td>\n      <td>0.620690</td>\n      <td>0.922653</td>\n      <td>1.081903</td>\n      <td>0.894147</td>\n      <td>0.623053</td>\n      <td>0.953635</td>\n      <td>0.705496</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.429167</td>\n      <td>1978</td>\n      <td>0.469828</td>\n      <td>34.770717</td>\n      <td>-9.395642</td>\n      <td>0.674483</td>\n      <td>0.413474</td>\n      <td>0.700044</td>\n      <td>20</td>\n      <td>...</td>\n      <td>False</td>\n      <td>0.664444</td>\n      <td>0.922604</td>\n      <td>1.026985</td>\n      <td>0.791310</td>\n      <td>0.622992</td>\n      <td>0.953516</td>\n      <td>0.705496</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.006849</td>\n      <td>0</td>\n      <td>1.135593</td>\n      <td>36.115056</td>\n      <td>-6.279268</td>\n      <td>0.907618</td>\n      <td>0.988636</td>\n      <td>0.700044</td>\n      <td>0</td>\n      <td>...</td>\n      <td>True</td>\n      <td>1.200070</td>\n      <td>0.922604</td>\n      <td>0.598954</td>\n      <td>0.791310</td>\n      <td>0.857747</td>\n      <td>0.976612</td>\n      <td>1.161586</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.0</td>\n      <td>0.234811</td>\n      <td>1639</td>\n      <td>0.234811</td>\n      <td>37.147432</td>\n      <td>-3.187555</td>\n      <td>0.744938</td>\n      <td>0.720877</td>\n      <td>0.817451</td>\n      <td>25</td>\n      <td>...</td>\n      <td>True</td>\n      <td>0.700661</td>\n      <td>0.430082</td>\n      <td>0.598954</td>\n      <td>0.791310</td>\n      <td>0.622992</td>\n      <td>0.680494</td>\n      <td>0.677816</td>\n      <td>14</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50.0</td>\n      <td>0.391156</td>\n      <td>28</td>\n      <td>0.440994</td>\n      <td>39.286124</td>\n      <td>-6.972403</td>\n      <td>0.907618</td>\n      <td>1.025391</td>\n      <td>1.142857</td>\n      <td>6922</td>\n      <td>...</td>\n      <td>False</td>\n      <td>0.849675</td>\n      <td>0.480203</td>\n      <td>0.598731</td>\n      <td>0.791271</td>\n      <td>0.623053</td>\n      <td>0.976431</td>\n      <td>1.161259</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74240</th>\n      <td>0.0</td>\n      <td>0.702811</td>\n      <td>1183</td>\n      <td>0.623209</td>\n      <td>37.007726</td>\n      <td>-3.280868</td>\n      <td>0.744714</td>\n      <td>0.633807</td>\n      <td>0.731299</td>\n      <td>350</td>\n      <td>...</td>\n      <td>False</td>\n      <td>0.700661</td>\n      <td>0.537885</td>\n      <td>1.081903</td>\n      <td>0.791310</td>\n      <td>0.857615</td>\n      <td>0.655623</td>\n      <td>0.677816</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74242</th>\n      <td>0.0</td>\n      <td>0.849020</td>\n      <td>0</td>\n      <td>0.889418</td>\n      <td>33.724987</td>\n      <td>-8.940758</td>\n      <td>0.674232</td>\n      <td>0.891332</td>\n      <td>0.814178</td>\n      <td>0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>0.700661</td>\n      <td>0.702026</td>\n      <td>0.688219</td>\n      <td>0.791271</td>\n      <td>0.623053</td>\n      <td>0.735928</td>\n      <td>0.677816</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74243</th>\n      <td>0.0</td>\n      <td>1.315789</td>\n      <td>1188</td>\n      <td>0.835007</td>\n      <td>33.963539</td>\n      <td>-1.429477</td>\n      <td>0.908266</td>\n      <td>1.070122</td>\n      <td>0.934446</td>\n      <td>95</td>\n      <td>...</td>\n      <td>False</td>\n      <td>0.849885</td>\n      <td>0.922653</td>\n      <td>1.026907</td>\n      <td>0.791290</td>\n      <td>0.623053</td>\n      <td>1.560209</td>\n      <td>1.161586</td>\n      <td>29</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>74246</th>\n      <td>50.0</td>\n      <td>1.066667</td>\n      <td>1428</td>\n      <td>1.066667</td>\n      <td>35.630481</td>\n      <td>-7.710549</td>\n      <td>0.674232</td>\n      <td>0.413474</td>\n      <td>0.819620</td>\n      <td>1</td>\n      <td>...</td>\n      <td>True</td>\n      <td>0.700586</td>\n      <td>0.922604</td>\n      <td>0.598731</td>\n      <td>0.791310</td>\n      <td>1.943795</td>\n      <td>0.680494</td>\n      <td>0.677781</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>74247</th>\n      <td>50.0</td>\n      <td>0.463333</td>\n      <td>965</td>\n      <td>0.822742</td>\n      <td>35.432998</td>\n      <td>-10.639270</td>\n      <td>1.183882</td>\n      <td>0.816976</td>\n      <td>0.813999</td>\n      <td>900</td>\n      <td>...</td>\n      <td>True</td>\n      <td>1.647846</td>\n      <td>0.922629</td>\n      <td>0.598731</td>\n      <td>0.791271</td>\n      <td>1.943795</td>\n      <td>0.735719</td>\n      <td>0.677816</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>53460 rows Ã— 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data_train_with_target = pd.concat([data_train, y_train], axis=1, join='inner')\n",
    "data_train_with_target.columns = list(data_train.columns) + ['status_group']\n",
    "data_train_with_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loaded wrangled-labeled-data-test-2d7d3126b4f539a5c747b7bed497626b.csv\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 5940 entries, 4 to 74229\nData columns (total 22 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   amount_tsh         5940 non-null   float64\n 1   funder             5843 non-null   float64\n 2   gps_height         5940 non-null   int64  \n 3   installer          5844 non-null   float64\n 4   longitude          5940 non-null   float64\n 5   latitude           5940 non-null   float64\n 6   basin              5940 non-null   float64\n 7   region_code        5940 non-null   float64\n 8   district_code      5940 non-null   float64\n 9   population         5940 non-null   int64  \n 10  public_meeting     5940 non-null   bool   \n 11  scheme_management  5940 non-null   float64\n 12  scheme_name        5891 non-null   float64\n 13  permit             5940 non-null   bool   \n 14  extraction_type    5940 non-null   float64\n 15  management         5940 non-null   float64\n 16  payment_type       5940 non-null   float64\n 17  water_quality      5940 non-null   float64\n 18  quantity           5940 non-null   float64\n 19  source             5940 non-null   float64\n 20  waterpoint_type    5940 non-null   float64\n 21  pump_age           5940 non-null   int64  \ndtypes: bool(2), float64(17), int64(3)\nmemory usage: 986.1 KB\n"
    }
   ],
   "source": [
    "fname = scjpnutils.get_data_fname(data_config, data_kwargs={'is_labels':False,'type':'test','is_cached':is_data_cached})\n",
    "data_test = pd.read_csv(fname, index_col=0).sort_index()\n",
    "print(f\"loaded {fname}\\n\")\n",
    "\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([    4,     6,    40,    41,    46,    66,    75,    84,    96,\n              105,\n            ...\n            74140, 74145, 74158, 74166, 74177, 74195, 74199, 74214, 74215,\n            74229],\n           dtype='int64', name='id', length=5940)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "data_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loaded labels-test-2d7d3126b4f539a5c747b7bed497626b.csv\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 5940 entries, 4 to 74229\nData columns (total 1 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   status_group  5940 non-null   object\ndtypes: object(1)\nmemory usage: 92.8+ KB\n"
    }
   ],
   "source": [
    "fname = scjpnutils.get_data_fname(data_config, data_kwargs={'is_labels':True,'type':'test','is_cached':is_data_cached})\n",
    "y_test = pd.read_csv(fname, index_col=0).sort_index()\n",
    "print(f\"loaded {fname}\\n\")\n",
    "\n",
    "y_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([    4,     6,    40,    41,    46,    66,    75,    84,    96,\n              105,\n            ...\n            74140, 74145, 74158, 74166, 74177, 74195, 74199, 74214, 74215,\n            74229],\n           dtype='int64', name='id', length=5940)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "y_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 0, 1])"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "y_test = let_labels.fit_transform(y_test)\n",
    "y_test.status_group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['functional', 'functional needs repair', 'non functional'],\n      dtype=object)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "let_labels.labelencoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_test = list(let_labels.labelencoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "<h2>Build Models (Run Trials)</h2>\n",
    "\n",
    "<h3>General functions for building Classifiers and running trials</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to render HTML and optionally log (append) it to file\n",
    "def render_HTML(the_html, fname=None):\n",
    "    display(HTML(the_html))\n",
    "    if fname is not None:\n",
    "        fm.append_text_file(BeautifulSoup(the_html).text + '\\n', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trials_log_fname(clf):\n",
    "    return f\"{clf.__class__.__name__}-trials.log\" if LOG_MODEL_TRIALS else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_find_best_params(clf, param_grid):\n",
    "    render_HTML(f\"<br><br>param_grid for {clf.__class__.__name__} GridSearch:<br><pre>{params}</pre>\", fname=get_trials_log_fname(clf))\n",
    "    grid_clf = GridSearchCV(\n",
    "        clf, \n",
    "        param_grid, \n",
    "        cv=K, \n",
    "        n_jobs=-1\n",
    "        , verbose=20\n",
    "    )\n",
    "    # with joblib.parallel_backend('dask'):\n",
    "    #     %time _ = grid_clf.fit(data_train, y_train)\n",
    "    %time _ = grid_clf.fit(data_train, y_train)\n",
    "    return grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_fit(clf, data_train, y_train):\n",
    "    # with joblib.parallel_backend('dask'):\n",
    "    #     %time clf.fit(data_train, y_train)\n",
    "    %time clf.fit(data_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_preds(clf, X, y, preds, dataset_name, classes):\n",
    "    render_HTML(\"<p><br>\", fname=get_trials_log_fname(clf))\n",
    "    _accuracy = accuracy_score(y, preds)\n",
    "    render_HTML(f\"{dataset_name} Accuracy: {round(_accuracy*100,4)}\", fname=get_trials_log_fname(clf))\n",
    "    render_HTML(\"<p><br>\", fname=get_trials_log_fname(clf))\n",
    "    render_HTML(f\"<pre>{classification_report(y, preds, target_names=classes)}</pre>\", fname=get_trials_log_fname(clf))\n",
    "    return _accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_run_trial(clf, params_to_try, best_parameters_so_far, run_trials_gridsearch=False):\n",
    "    if run_trials_gridsearch:\n",
    "        for param_name, param_value in best_parameters_so_far.items():\n",
    "            params_to_try.update({param_name: [param_value]})\n",
    "        best_parameters = gs_find_best_params(clf, params_to_try)\n",
    "    else:\n",
    "        best_parameters = params_to_try\n",
    "    best_parameters_so_far.update(best_parameters)\n",
    "\n",
    "    render_HTML(\"<p><br>\", fname=get_trials_log_fname(clf))\n",
    "    render_HTML(f\"Grid Search {'(previously) ' if not run_trials_gridsearch else ''}found the following optimal parameters: \", fname=get_trials_log_fname(clf))\n",
    "    render_HTML(f\"<pre>{pprint.pformat(best_parameters_so_far, indent=4)}</pre>\", fname=get_trials_log_fname(clf))\n",
    "\n",
    "    render_HTML(\"<p><br>\", fname=get_trials_log_fname(clf))\n",
    "    render_HTML(\"Fitting classifier...\", fname=get_trials_log_fname(clf))\n",
    "    clf = clf.set_params(**best_parameters_so_far)\n",
    "    clf = clf_fit(clf, data_train, y_train)\n",
    "    s_all_done = \"\\tALL DONE!\"\n",
    "    render_HTML(f\"<pre>{s_all_done}</pre>\", fname=get_trials_log_fname(clf))\n",
    "\n",
    "    render_HTML(\"<p><br>\", fname=get_trials_log_fname(clf))\n",
    "    render_HTML(\"Predicting labels on training data...\", fname=get_trials_log_fname(clf))\n",
    "    pred_train = clf.predict(data_train)\n",
    "    render_HTML(f\"<pre>{s_all_done}</pre>\", fname=get_trials_log_fname(clf))\n",
    "    _accuracy_train = summarize_preds(clf, data_train, y_train, pred_train, 'Training', classes_train)\n",
    "\n",
    "    if not run_trials_gridsearch:\n",
    "        render_HTML(\"<p><br>\")\n",
    "        render_HTML(\"Computing cross-val score on training data...\")\n",
    "        cv_score_train = cross_val_score(clf, data_train, y_train, cv=cross_val_score_K)\n",
    "        render_HTML(f\"<pre>{s_all_done} scores: {cv_score_train}</pre>\")\n",
    "        render_HTML(f\"cross_val_score: {np.mean(cv_score_train)}\")\n",
    "\n",
    "    render_HTML(\"<p><br>\", fname=get_trials_log_fname(clf))\n",
    "    render_HTML(f\"Predicting labels on testing data...\", fname=get_trials_log_fname(clf))\n",
    "    pred_test = clf.predict(data_test)\n",
    "    render_HTML(f\"<pre>{s_all_done}</pre>\", fname=get_trials_log_fname(clf))\n",
    "    _accuracy_test = summarize_preds(clf, data_test, y_test, pred_test, 'Testing', classes_test)\n",
    "    \n",
    "    if not run_trials_gridsearch:\n",
    "        render_HTML(\"<p><br>\")\n",
    "        render_HTML(f\"Computing cross-val score on testing data...\")\n",
    "        cv_score_test = cross_val_score(clf, data_test, y_test, cv=cross_val_score_K)\n",
    "        render_HTML(f\"<pre>{s_all_done} scores: {cv_score_test}</pre>\")\n",
    "        render_HTML(f\"cross_val_score: {np.mean(cv_score_test)}\")\n",
    "\n",
    "    _class_name = clf.__class__.__name__\n",
    "    model_results['modeling_results'][_class_name] = {}\n",
    "    model_results['modeling_results'][_class_name]['accuracy'] = {}\n",
    "    model_results['modeling_results'][_class_name]['accuracy']['train'] = _accuracy_train\n",
    "    model_results['modeling_results'][_class_name]['accuracy']['test'] = _accuracy_test\n",
    "    model_results['modeling_results'][_class_name]['feature_importances'] = get_feat_importances(clf)\n",
    "    render_HTML(\"<p><br>\", fname=get_trials_log_fname(clf))\n",
    "    render_HTML(\"Feature Importances:\", fname=get_trials_log_fname(clf))\n",
    "    render_HTML(f\"<pre>{pprint.pformat(model_results['modeling_results'][_class_name]['feature_importances'], indent=4)}</pre><p><br><br>\", fname=get_trials_log_fname(clf))\n",
    "\n",
    "    return clf, best_parameters_so_far, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_importances(clf):\n",
    "    feat_importances = {}\n",
    "    for i, feat in enumerate(list(data_train.columns)):\n",
    "        feat_importances[feat] = clf.feature_importances_[i]\n",
    "    return sorted(list(feat_importances.items()), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "<h2>Initialize Dask-Client (to Dask backend for parallelization) <i>(DISABLED for now)</i></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_config['dask']['use']:\n",
    "    if models_config['dask']['is_remote']:\n",
    "        # for Kubernetes dask scheduler/worker cluster in GCP - but this costs money to run the cluster AND requires a lot more work for data parallelization!\n",
    "        dask_client = Client(f'tcp://{models_config['dask']['remote']['scheduler_address']}:8786')\n",
    "    else:\n",
    "        # local\n",
    "        dask_client = Client( #spawns a local cluster\n",
    "            n_workers=models_config['dask']['local']['n_workers'], \n",
    "            threads_per_worker=models_config['dask']['local']['n_jobs'], \n",
    "            memory_limit=models_config['dask']['local']['memory_limit'] # memory_limit is per worker\n",
    "        )\n",
    "\n",
    "    dask_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "<h3>Decision Tree Classifier</h3>\n",
    "<h4>Trials</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "models_config['DecisionTreeClassifier']['trials']['run']: False"
     },
     "metadata": {}
    }
   ],
   "source": [
    "run_dtclf = models_config['DecisionTreeClassifier']['run']\n",
    "render_HTML(f\"models_config['DecisionTreeClassifier']['run']: {run_rfclf}\")\n",
    "\n",
    "if run_dtclf:\n",
    "    trials = models_config['DecisionTreeClassifier']['trials']\n",
    "\n",
    "    display(HTML(f\"models_config['DecisionTreeClassifier']['trials']['run']: {trials['run']}\"))\n",
    "    if trials['run']:\n",
    "        trials_list = trials['array']\n",
    "\n",
    "        best_parameters = {}\n",
    "        for i, trial in enumerate(trials_list):\n",
    "            display(HTML(f\"<p><br>trial[{i}]['gridsearch']['run']: {trial['gridsearch']['run']}<br>\"))\n",
    "            params = trial['gridsearch']['last_best'] if not trial['gridsearch']['run'] else trial['gridsearch']['param_grid']\n",
    "            rfclf, best_parameters, model_results = clf_run_trial(DecisionTreeClassifier(), params, best_parameters, run_trials_gridsearch=trial['gridsearch']['run']) # note that best_parameters will be set to those used in the last trial\n",
    "\n",
    "    else:\n",
    "        best_parameters = models_config['DecisionTreeClassifier']['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "<h4>Build Final Model with best params</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_dtclf:\n",
    "    best_parameters.update({'random_state': SEED})\n",
    "    dtclf, _, model_results = clf_run_trial(DecisionTreeClassifier(), best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "<h3>Random Forest Classifier</h3>\n",
    "<h4>Trials</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "models_config['RandomForestClassifier']['trials']['run']: False"
     },
     "metadata": {}
    }
   ],
   "source": [
    "run_rfclf = models_config['RandomForestClassifier']['run']\n",
    "render_HTML(f\"models_config['RandomForestClassifier']['run']: {run_rfclf}\")\n",
    "\n",
    "if run_rfclf:\n",
    "    trials = models_config['RandomForestClassifier']['trials']\n",
    "\n",
    "    render_HTML(f\"models_config['RandomForestClassifier']['trials']['run']: {trials['run']}\")\n",
    "    if trials['run']:\n",
    "        trials_list = trials['array']\n",
    "\n",
    "        for i, trial in enumerate(trials_list):\n",
    "            render_HTML(f\"<p><br>trial[{i}]['gridsearch']['run']: {trial['gridsearch']['run']}<br>\")\n",
    "            params = trial['gridsearch']['last_best'] if not trial['gridsearch']['run'] else trial['gridsearch']['param_grid']\n",
    "            if trial['gridsearch']['run']:\n",
    "                params.update({'n_jobs': [-1]})\n",
    "            else:\n",
    "                params.update({'n_jobs':-1})\n",
    "            rfclf, best_parameters, model_results = clf_run_trial(RandomForestClassifier(), params, run_trials_gridsearch=trial['gridsearch']['run']) # note that best_parameters will be set to those used in the last trial\n",
    "\n",
    "    else:\n",
    "        best_parameters = models_config['RandomForestClassifier']['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "<h4>Build Final Model with best params</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_rfclf:\n",
    "    best_parameters.update({'n_jobs':-1, 'verbose':1, 'random_state': SEED})\n",
    "    rfclf, _ , model_results = clf_run_trial(RandomForestClassifier(), best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br><br><br>\n",
    "<h3>XGBClassifier</h3>\n",
    "<h4>Trials</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "models_config['XGBClassifier']['trials']['run']: True"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>trial[0]['gridsearch']['run']: True<br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br><br>param_grid for XGBClassifier GridSearch:<br><pre>{'n_estimators': [100, 500, 750, 1000], 'n_jobs': [-1]}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   35.1s\n[Parallel(n_jobs=-1)]: Done   2 out of  12 | elapsed:   35.5s remaining:  3.0min\n[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:   35.6s remaining:  1.8min\n[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:  2.8min remaining:  5.7min\n[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:  2.9min remaining:  4.0min\n[Parallel(n_jobs=-1)]: Done   6 out of  12 | elapsed:  2.9min remaining:  2.9min\n[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:  4.0min remaining:  2.8min\n[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:  4.0min remaining:  2.0min\n[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:  4.4min remaining:  1.5min\n[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:  5.0min remaining:  1.0min\n[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  6.2min remaining:    0.0s\n[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  6.2min finished\nCPU times: user 6min 44s, sys: 4.09 s, total: 6min 48s\nWall time: 7min 10s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Grid Search found the following optimal parameters: "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>{'n_estimators': 1000, 'n_jobs': -1}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Fitting classifier..."
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 7min 31s, sys: 4.01 s, total: 7min 35s\nWall time: 1min 3s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on training data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Training Accuracy: 95.6884"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       0.94      0.99      0.96     28991\nfunctional needs repair       0.98      0.79      0.87      3885\n         non functional       0.98      0.95      0.96     20584\n\n               accuracy                           0.96     53460\n              macro avg       0.97      0.91      0.93     53460\n           weighted avg       0.96      0.96      0.96     53460\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on testing data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Testing Accuracy: 94.7643"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       0.94      0.98      0.96      3268\nfunctional needs repair       0.99      0.76      0.86       432\n         non functional       0.96      0.94      0.95      2240\n\n               accuracy                           0.95      5940\n              macro avg       0.96      0.89      0.92      5940\n           weighted avg       0.95      0.95      0.95      5940\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Feature Importances:"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>[   ('quantity', 0.32386532),\n    ('waterpoint_type', 0.1512152),\n    ('scheme_name', 0.073495984),\n    ('funder', 0.0687266),\n    ('extraction_type', 0.06781703),\n    ('source', 0.040350854),\n    ('payment_type', 0.03956658),\n    ('installer', 0.03253351),\n    ('region_code', 0.02498975),\n    ('longitude', 0.022537787),\n    ('amount_tsh', 0.019278314),\n    ('pump_age', 0.018746719),\n    ('basin', 0.018426565),\n    ('public_meeting', 0.014328463),\n    ('permit', 0.013977598),\n    ('latitude', 0.013712486),\n    ('scheme_management', 0.011502477),\n    ('population', 0.010887528),\n    ('district_code', 0.010249805),\n    ('management', 0.009410875),\n    ('gps_height', 0.008149564),\n    ('water_quality', 0.006230921)]</pre><p><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>trial[1]['gridsearch']['run']: True<br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br><br>param_grid for XGBClassifier GridSearch:<br><pre>{'max_depth': [3, 5, 10, 22, 50], 'n_jobs': [-1], 'n_estimators': [1000]}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  5.4min\n[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:  5.5min remaining: 35.7min\n[Parallel(n_jobs=-1)]: Done   3 out of  15 | elapsed:  5.5min remaining: 22.0min\n[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:  8.1min remaining: 22.4min\n[Parallel(n_jobs=-1)]: Done   5 out of  15 | elapsed:  8.3min remaining: 16.6min\n[Parallel(n_jobs=-1)]: Done   6 out of  15 | elapsed:  8.3min remaining: 12.5min\n[Parallel(n_jobs=-1)]: Done   7 out of  15 | elapsed: 15.0min remaining: 17.1min\n[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed: 15.3min remaining: 13.4min\n[Parallel(n_jobs=-1)]: Done   9 out of  15 | elapsed: 19.9min remaining: 13.3min\n[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed: 26.9min remaining: 13.4min\n[Parallel(n_jobs=-1)]: Done  11 out of  15 | elapsed: 27.3min remaining:  9.9min\n[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed: 29.1min remaining:  7.3min\n[Parallel(n_jobs=-1)]: Done  13 out of  15 | elapsed: 29.8min remaining:  4.6min\n[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 34.0min remaining:    0.0s\n[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 34.0min finished\nCPU times: user 20min 24s, sys: 17.3 s, total: 20min 42s\nWall time: 37min 6s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Grid Search found the following optimal parameters: "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>{'max_depth': 10, 'n_estimators': 1000, 'n_jobs': -1}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Fitting classifier..."
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 20min 15s, sys: 16.6 s, total: 20min 31s\nWall time: 3min 4s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on training data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Training Accuracy: 100.0"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       1.00      1.00      1.00     28991\nfunctional needs repair       1.00      1.00      1.00      3885\n         non functional       1.00      1.00      1.00     20584\n\n               accuracy                           1.00     53460\n              macro avg       1.00      1.00      1.00     53460\n           weighted avg       1.00      1.00      1.00     53460\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on testing data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Testing Accuracy: 96.936"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       0.97      0.98      0.98      3268\nfunctional needs repair       0.97      0.85      0.91       432\n         non functional       0.97      0.97      0.97      2240\n\n               accuracy                           0.97      5940\n              macro avg       0.97      0.94      0.95      5940\n           weighted avg       0.97      0.97      0.97      5940\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Feature Importances:"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>[   ('quantity', 0.25796747),\n    ('waterpoint_type', 0.13392983),\n    ('scheme_name', 0.10337945),\n    ('funder', 0.0950277),\n    ('installer', 0.047091503),\n    ('extraction_type', 0.037050005),\n    ('region_code', 0.03093112),\n    ('payment_type', 0.028307157),\n    ('amount_tsh', 0.02729481),\n    ('source', 0.027091356),\n    ('pump_age', 0.026038716),\n    ('longitude', 0.023390654),\n    ('district_code', 0.020146923),\n    ('basin', 0.019814754),\n    ('latitude', 0.019353732),\n    ('public_meeting', 0.01704544),\n    ('gps_height', 0.016919795),\n    ('scheme_management', 0.016001739),\n    ('permit', 0.015013997),\n    ('population', 0.014995132),\n    ('management', 0.013562274),\n    ('water_quality', 0.009646492)]</pre><p><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>trial[2]['gridsearch']['run']: True<br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br><br>param_grid for XGBClassifier GridSearch:<br><pre>{'learning_rate': [0.1, 0.3, 0.6, 1.0], 'n_jobs': [-1], 'n_estimators': [1000], 'max_depth': [10]}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 12.2min\n[Parallel(n_jobs=-1)]: Done   2 out of  12 | elapsed: 12.5min remaining: 62.3min\n[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed: 13.5min remaining: 40.5min\n[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed: 13.8min remaining: 27.6min\n[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed: 13.9min remaining: 19.4min\n[Parallel(n_jobs=-1)]: Done   6 out of  12 | elapsed: 14.8min remaining: 14.8min\n[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed: 15.1min remaining: 10.8min\n[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed: 15.1min remaining:  7.6min\n[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed: 19.9min remaining:  6.6min\n[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed: 20.6min remaining:  4.1min\n[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 20.8min remaining:    0.0s\n[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 20.8min finished\nCPU times: user 18min 20s, sys: 15.2 s, total: 18min 35s\nWall time: 23min 40s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Grid Search found the following optimal parameters: "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>{'learning_rate': 0.3, 'max_depth': 10, 'n_estimators': 1000, 'n_jobs': -1}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Fitting classifier..."
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 19min, sys: 16.1 s, total: 19min 16s\nWall time: 2min 59s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on training data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Training Accuracy: 100.0"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       1.00      1.00      1.00     28991\nfunctional needs repair       1.00      1.00      1.00      3885\n         non functional       1.00      1.00      1.00     20584\n\n               accuracy                           1.00     53460\n              macro avg       1.00      1.00      1.00     53460\n           weighted avg       1.00      1.00      1.00     53460\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on testing data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Testing Accuracy: 96.9529"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       0.97      0.98      0.98      3268\nfunctional needs repair       0.95      0.85      0.90       432\n         non functional       0.97      0.97      0.97      2240\n\n               accuracy                           0.97      5940\n              macro avg       0.96      0.94      0.95      5940\n           weighted avg       0.97      0.97      0.97      5940\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Feature Importances:"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>[   ('quantity', 0.24877883),\n    ('waterpoint_type', 0.15510912),\n    ('scheme_name', 0.10097765),\n    ('funder', 0.08329094),\n    ('installer', 0.043627173),\n    ('extraction_type', 0.039869927),\n    ('amount_tsh', 0.031698585),\n    ('region_code', 0.0302173),\n    ('payment_type', 0.028295545),\n    ('source', 0.026408885),\n    ('pump_age', 0.025933718),\n    ('longitude', 0.021508215),\n    ('basin', 0.021200772),\n    ('district_code', 0.02031674),\n    ('latitude', 0.018267099),\n    ('public_meeting', 0.017914211),\n    ('gps_height', 0.016972652),\n    ('permit', 0.016208358),\n    ('scheme_management', 0.016150203),\n    ('population', 0.01583859),\n    ('management', 0.011399046),\n    ('water_quality', 0.010016482)]</pre><p><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>trial[3]['gridsearch']['run']: True<br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br><br>param_grid for XGBClassifier GridSearch:<br><pre>{'min_child_weight': [1, 3, 5], 'n_jobs': [-1], 'n_estimators': [1000], 'max_depth': [10], 'learning_rate': [0.3]}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 13.1min\n[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed: 13.2min remaining: 46.2min\n[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed: 13.5min remaining: 27.0min\n[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed: 13.7min remaining: 17.1min\n[Parallel(n_jobs=-1)]: Done   5 out of   9 | elapsed: 13.7min remaining: 10.9min\n[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed: 13.7min remaining:  6.8min\n[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed: 14.0min remaining:  4.0min\n[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 20.5min remaining:    0.0s\n[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 20.5min finished\nCPU times: user 19min 42s, sys: 16.8 s, total: 19min 59s\nWall time: 23min 35s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Grid Search found the following optimal parameters: "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>{   'learning_rate': 0.3,\n    'max_depth': 10,\n    'min_child_weight': 1,\n    'n_estimators': 1000,\n    'n_jobs': -1}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Fitting classifier..."
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 19min 33s, sys: 16 s, total: 19min 49s\nWall time: 3min 1s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on training data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Training Accuracy: 100.0"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       1.00      1.00      1.00     28991\nfunctional needs repair       1.00      1.00      1.00      3885\n         non functional       1.00      1.00      1.00     20584\n\n               accuracy                           1.00     53460\n              macro avg       1.00      1.00      1.00     53460\n           weighted avg       1.00      1.00      1.00     53460\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on testing data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Testing Accuracy: 96.9529"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       0.97      0.98      0.98      3268\nfunctional needs repair       0.95      0.85      0.90       432\n         non functional       0.97      0.97      0.97      2240\n\n               accuracy                           0.97      5940\n              macro avg       0.96      0.94      0.95      5940\n           weighted avg       0.97      0.97      0.97      5940\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Feature Importances:"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>[   ('quantity', 0.24877883),\n    ('waterpoint_type', 0.15510912),\n    ('scheme_name', 0.10097765),\n    ('funder', 0.08329094),\n    ('installer', 0.043627173),\n    ('extraction_type', 0.039869927),\n    ('amount_tsh', 0.031698585),\n    ('region_code', 0.0302173),\n    ('payment_type', 0.028295545),\n    ('source', 0.026408885),\n    ('pump_age', 0.025933718),\n    ('longitude', 0.021508215),\n    ('basin', 0.021200772),\n    ('district_code', 0.02031674),\n    ('latitude', 0.018267099),\n    ('public_meeting', 0.017914211),\n    ('gps_height', 0.016972652),\n    ('permit', 0.016208358),\n    ('scheme_management', 0.016150203),\n    ('population', 0.01583859),\n    ('management', 0.011399046),\n    ('water_quality', 0.010016482)]</pre><p><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>trial[4]['gridsearch']['run']: True<br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br><br>param_grid for XGBClassifier GridSearch:<br><pre>{'subsample': [0.1, 0.25, 0.5, 1.0], 'n_jobs': [-1], 'n_estimators': [1000], 'max_depth': [10], 'learning_rate': [0.3], 'min_child_weight': [1]}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  8.8min\n[Parallel(n_jobs=-1)]: Done   2 out of  12 | elapsed:  9.0min remaining: 45.0min\n[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:  9.0min remaining: 27.1min\n[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed: 10.4min remaining: 20.8min\n[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed: 10.5min remaining: 14.7min\n[Parallel(n_jobs=-1)]: Done   6 out of  12 | elapsed: 10.6min remaining: 10.6min\n[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed: 12.1min remaining:  8.6min\n[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed: 12.3min remaining:  6.1min\n[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed: 17.0min remaining:  5.7min\n[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed: 18.1min remaining:  3.6min\n[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 19.1min remaining:    0.0s\n[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 19.1min finished\nCPU times: user 18min 12s, sys: 14.2 s, total: 18min 27s\nWall time: 21min 52s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Grid Search found the following optimal parameters: "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>{   'learning_rate': 0.3,\n    'max_depth': 10,\n    'min_child_weight': 1,\n    'n_estimators': 1000,\n    'n_jobs': -1,\n    'subsample': 1.0}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Fitting classifier..."
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 18min 26s, sys: 14.7 s, total: 18min 40s\nWall time: 2min 45s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on training data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Training Accuracy: 100.0"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       1.00      1.00      1.00     28991\nfunctional needs repair       1.00      1.00      1.00      3885\n         non functional       1.00      1.00      1.00     20584\n\n               accuracy                           1.00     53460\n              macro avg       1.00      1.00      1.00     53460\n           weighted avg       1.00      1.00      1.00     53460\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on testing data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Testing Accuracy: 96.9529"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       0.97      0.98      0.98      3268\nfunctional needs repair       0.95      0.85      0.90       432\n         non functional       0.97      0.97      0.97      2240\n\n               accuracy                           0.97      5940\n              macro avg       0.96      0.94      0.95      5940\n           weighted avg       0.97      0.97      0.97      5940\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Feature Importances:"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>[   ('quantity', 0.24877883),\n    ('waterpoint_type', 0.15510912),\n    ('scheme_name', 0.10097765),\n    ('funder', 0.08329094),\n    ('installer', 0.043627173),\n    ('extraction_type', 0.039869927),\n    ('amount_tsh', 0.031698585),\n    ('region_code', 0.0302173),\n    ('payment_type', 0.028295545),\n    ('source', 0.026408885),\n    ('pump_age', 0.025933718),\n    ('longitude', 0.021508215),\n    ('basin', 0.021200772),\n    ('district_code', 0.02031674),\n    ('latitude', 0.018267099),\n    ('public_meeting', 0.017914211),\n    ('gps_height', 0.016972652),\n    ('permit', 0.016208358),\n    ('scheme_management', 0.016150203),\n    ('population', 0.01583859),\n    ('management', 0.011399046),\n    ('water_quality', 0.010016482)]</pre><p><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>trial[5]['gridsearch']['run']: True<br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br><br>param_grid for XGBClassifier GridSearch:<br><pre>{'gamma': [0, 1, 2, 5, 10], 'n_jobs': [-1], 'n_estimators': [1000], 'max_depth': [10], 'learning_rate': [0.3], 'min_child_weight': [1], 'subsample': [1.0]}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 13.3min\n[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed: 13.6min remaining: 88.4min\n[Parallel(n_jobs=-1)]: Done   3 out of  15 | elapsed: 13.7min remaining: 54.8min\n[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed: 14.4min remaining: 39.6min\n[Parallel(n_jobs=-1)]: Done   5 out of  15 | elapsed: 14.5min remaining: 29.0min\n[Parallel(n_jobs=-1)]: Done   6 out of  15 | elapsed: 15.1min remaining: 22.6min\n[Parallel(n_jobs=-1)]: Done   7 out of  15 | elapsed: 15.1min remaining: 17.2min\n[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed: 16.4min remaining: 14.3min\n[Parallel(n_jobs=-1)]: Done   9 out of  15 | elapsed: 26.4min remaining: 17.6min\n[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed: 27.5min remaining: 13.7min\n[Parallel(n_jobs=-1)]: Done  11 out of  15 | elapsed: 27.7min remaining: 10.1min\n[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed: 27.8min remaining:  6.9min\n[Parallel(n_jobs=-1)]: Done  13 out of  15 | elapsed: 27.9min remaining:  4.3min\n[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 28.7min remaining:    0.0s\n[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 28.7min finished\nCPU times: user 17min 51s, sys: 13.4 s, total: 18min 5s\nWall time: 31min 23s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Grid Search found the following optimal parameters: "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>{   'gamma': 0,\n    'learning_rate': 0.3,\n    'max_depth': 10,\n    'min_child_weight': 1,\n    'n_estimators': 1000,\n    'n_jobs': -1,\n    'subsample': 1.0}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Fitting classifier..."
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 18min 16s, sys: 14.5 s, total: 18min 31s\nWall time: 2min 47s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on training data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Training Accuracy: 100.0"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       1.00      1.00      1.00     28991\nfunctional needs repair       1.00      1.00      1.00      3885\n         non functional       1.00      1.00      1.00     20584\n\n               accuracy                           1.00     53460\n              macro avg       1.00      1.00      1.00     53460\n           weighted avg       1.00      1.00      1.00     53460\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on testing data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Testing Accuracy: 96.9529"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       0.97      0.98      0.98      3268\nfunctional needs repair       0.95      0.85      0.90       432\n         non functional       0.97      0.97      0.97      2240\n\n               accuracy                           0.97      5940\n              macro avg       0.96      0.94      0.95      5940\n           weighted avg       0.97      0.97      0.97      5940\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Feature Importances:"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>[   ('quantity', 0.24877883),\n    ('waterpoint_type', 0.15510912),\n    ('scheme_name', 0.10097765),\n    ('funder', 0.08329094),\n    ('installer', 0.043627173),\n    ('extraction_type', 0.039869927),\n    ('amount_tsh', 0.031698585),\n    ('region_code', 0.0302173),\n    ('payment_type', 0.028295545),\n    ('source', 0.026408885),\n    ('pump_age', 0.025933718),\n    ('longitude', 0.021508215),\n    ('basin', 0.021200772),\n    ('district_code', 0.02031674),\n    ('latitude', 0.018267099),\n    ('public_meeting', 0.017914211),\n    ('gps_height', 0.016972652),\n    ('permit', 0.016208358),\n    ('scheme_management', 0.016150203),\n    ('population', 0.01583859),\n    ('management', 0.011399046),\n    ('water_quality', 0.010016482)]</pre><p><br><br>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "run_xgbclf = models_config['XGBClassifier']['run']\n",
    "render_HTML(f\"models_config['XGBClassifier']['run']: {run_xgbclf}\")\n",
    "\n",
    "if run_xgbclf:\n",
    "    trials = models_config['XGBClassifier']['trials']\n",
    "\n",
    "    render_HTML(f\"models_config['XGBClassifier']['trials']['run']: {trials['run']}\")\n",
    "    if trials['run']:\n",
    "        trials_list = trials['array']\n",
    "\n",
    "        best_parameters = {}\n",
    "        for i, trial in enumerate(trials_list):\n",
    "            render_HTML(f\"<p><br>trial[{i}]['gridsearch']['run']: {trial['gridsearch']['run']}<br>\")\n",
    "            params = trial['gridsearch']['last_best'] if not trial['gridsearch']['run'] else trial['gridsearch']['param_grid']\n",
    "            if trial['gridsearch']['run']:\n",
    "                params.update({'n_jobs': [-1]})\n",
    "            else:\n",
    "                params.update({'n_jobs':-1})\n",
    "            xgbclf, best_parameters, model_results = clf_run_trial(XGBClassifier(), params, best_parameters, run_trials_gridsearch=trial['gridsearch']['run']) # note that best_parameters will be set to those used in the last trial\n",
    "\n",
    "    else:\n",
    "        best_parameters = models_config['XGBClassifier']['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "<h4>Build Final Model with best params</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Grid Search (previously) found the following optimal parameters: "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>{   'gamma': 0,\n    'learning_rate': 0.3,\n    'max_depth': 10,\n    'min_child_weight': 1,\n    'n_estimators': 1000,\n    'n_jobs': -1,\n    'random_state': 42,\n    'subsample': 1.0,\n    'verbosity': 1}</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Fitting classifier..."
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 17min 57s, sys: 14.6 s, total: 18min 12s\nWall time: 2min 42s\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on training data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Training Accuracy: 100.0"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       1.00      1.00      1.00     28991\nfunctional needs repair       1.00      1.00      1.00      3885\n         non functional       1.00      1.00      1.00     20584\n\n               accuracy                           1.00     53460\n              macro avg       1.00      1.00      1.00     53460\n           weighted avg       1.00      1.00      1.00     53460\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Computing cross-val score on training data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE! scores: [0.96427235 0.96586233 0.96146652 0.9640853  0.96539469]</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "cross_val_score: 0.9642162364384588"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Predicting labels on testing data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE!</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Testing Accuracy: 96.9529"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>                         precision    recall  f1-score   support\n\n             functional       0.97      0.98      0.98      3268\nfunctional needs repair       0.95      0.85      0.90       432\n         non functional       0.97      0.97      0.97      2240\n\n               accuracy                           0.97      5940\n              macro avg       0.96      0.94      0.95      5940\n           weighted avg       0.97      0.97      0.97      5940\n</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Computing cross-val score on testing data..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>\tALL DONE! scores: [0.88131313 0.86195286 0.89309764 0.8973064  0.85774411]</pre>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "cross_val_score: 0.8782828282828283"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<p><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Feature Importances:"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<pre>[   ('quantity', 0.24877883),\n    ('waterpoint_type', 0.15510912),\n    ('scheme_name', 0.10097765),\n    ('funder', 0.08329094),\n    ('installer', 0.043627173),\n    ('extraction_type', 0.039869927),\n    ('amount_tsh', 0.031698585),\n    ('region_code', 0.0302173),\n    ('payment_type', 0.028295545),\n    ('source', 0.026408885),\n    ('pump_age', 0.025933718),\n    ('longitude', 0.021508215),\n    ('basin', 0.021200772),\n    ('district_code', 0.02031674),\n    ('latitude', 0.018267099),\n    ('public_meeting', 0.017914211),\n    ('gps_height', 0.016972652),\n    ('permit', 0.016208358),\n    ('scheme_management', 0.016150203),\n    ('population', 0.01583859),\n    ('management', 0.011399046),\n    ('water_quality', 0.010016482)]</pre><p><br><br>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "if run_xgbclf:\n",
    "    best_parameters.update({'n_jobs':-1, 'verbosity':1, 'random_state': SEED})\n",
    "    xgbclf, _ , model_results = clf_run_trial(XGBClassifier(), best_parameters, best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br><br>\n",
    "<h2>Save Results to File</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "updated models-results-2d7d3126b4f539a5c747b7bed497626b.json\n"
    }
   ],
   "source": [
    "fm.save_json(model_results, model_results_fname)\n",
    "print(f\"updated {model_results_fname}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python361064bitlearnenvconda6dc930ea082b425c82fd8a0b2d571658"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}